{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c74340a-a7d4-4237-b771-76ee73544cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "CSV_PATH = r\"C:\\Users\\Dell\\OneDrive\\Desktop\\infosys intern 6.0\\education_policies.csv\"\n",
    "TRAIN_PATH = r\"C:\\Users\\Dell\\OneDrive\\Desktop\\infosys intern 6.0\\train_policies.csv\"\n",
    "TEST_PATH = r\"C:\\Users\\Dell\\OneDrive\\Desktop\\infosys intern 6.0\\test_policies.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ce0d5be-1215-41b3-bdf5-d7d5f63f8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_policies(n=500):\n",
    "    states = [\"Karnataka\",\"Maharashtra\",\"Tamil Nadu\",\"Uttar Pradesh\",\"Delhi\",\n",
    "              \"Kerala\",\"West Bengal\",\"Gujarat\",\"Rajasthan\",\"Punjab\"]\n",
    "    sectors = [\"Primary\",\"Secondary\",\"Higher Education\",\"Vocational\",\"Early Childhood\"]\n",
    "    target_groups = [\"Students\",\"Teachers\",\"Rural Students\",\"Urban Students\",\n",
    "                     \"Women\",\"Disadvantaged Groups\",\"All\"]\n",
    "    statuses = [\"Proposed\",\"Implemented\",\"Under Review\",\"Pilot\"]\n",
    "    years = list(range(2015, 2026))\n",
    "    stakeholders_list = [\n",
    "        \"Ministry of Education, Local NGOs\",\n",
    "        \"State Education Department, Private Partners\",\n",
    "        \"Teachers' Unions, Community Leaders\",\n",
    "        \"Central Government, Donors\",\n",
    "        \"EdTech Companies, Universities\"\n",
    "    ]\n",
    "    funding_ranges = [(0.5,5),(5,20),(20,100),(0.1,0.5)]\n",
    "    aspects = [\"learning outcomes\",\"infrastructure\",\"teacher quality\",\n",
    "               \"digital access\",\"early childhood development\",\"vocational skills\"]\n",
    "    interventions = [\"grants to schools\",\"teacher training programs\",\"digital device distribution\",\n",
    "                     \"curriculum reform\",\"scholarship schemes\",\"public-private partnerships\"]\n",
    "    focuses = [\"marginalized communities\",\"gender equity\",\"rural accessibility\",\n",
    "               \"urban inclusion\",\"STEM education\",\"literacy and numeracy\"]\n",
    "    secondary_aspects = [\"community participation\",\"governance\",\"assessment quality\",\"safety standards\"]\n",
    "\n",
    "    records = []\n",
    "    for i in range(1, n+1):\n",
    "        policy_id = f\"P{1000+i}\"\n",
    "        title = f\"{random.choice(['National','State','District'])} {random.choice(sectors)} Education Reform {random.randint(1,99)}\"\n",
    "        sector = random.choice(sectors)\n",
    "        region = random.choice(states)\n",
    "        year = random.choice(years)\n",
    "        target_group = random.choice(target_groups)\n",
    "        status = random.choice(statuses)\n",
    "        funding = round(random.uniform(*random.choice(funding_ranges)), 2)\n",
    "        stakeholders = random.choice(stakeholders_list)\n",
    "        impact_score = round(random.uniform(0.1, 0.99), 3)\n",
    "        summary = f\"This policy aims to improve {random.choice(aspects)} in {sector} through {random.choice(interventions)} in {region}.\"\n",
    "        goals = f\"Increase reach by {random.randint(5,40)}% in {random.randint(1,5)} years.\"\n",
    "        full_text = f\"{summary} Goals: {goals}\"\n",
    "\n",
    "        records.append({\n",
    "            \"policy_id\": policy_id,\n",
    "            \"title\": title,\n",
    "            \"sector\": sector,\n",
    "            \"region\": region,\n",
    "            \"year\": year,\n",
    "            \"target_group\": target_group,\n",
    "            \"status\": status,\n",
    "            \"funding_million_usd\": funding,\n",
    "            \"stakeholders\": stakeholders,\n",
    "            \"impact_score\": impact_score,\n",
    "            \"summary\": summary,\n",
    "            \"goals\": goals,\n",
    "            \"full_text\": full_text\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25675e4-1c44-4aee-8fef-f18966541ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df[\"text_for_nlp\"] = (\n",
    "        df[\"title\"].astype(str) + \". \" +\n",
    "        df[\"full_text\"].astype(str) + \". Stakeholders: \" +\n",
    "        df[\"stakeholders\"].astype(str)\n",
    "    ).str.lower()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c07420a-6a9e-491d-9281-841d6157d4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared: 400 train, 100 test.\n"
     ]
    }
   ],
   "source": [
    "# Load existing dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\infosys intern 6.0\\education_policies.csv\")\n",
    "\n",
    "# Preprocess & split\n",
    "df = preprocess(df)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED, shuffle=True)\n",
    "\n",
    "# Save split datasets\n",
    "train_df.to_csv(TRAIN_PATH, index=False)\n",
    "test_df.to_csv(TEST_PATH, index=False)\n",
    "\n",
    "print(f\"Data prepared: {len(train_df)} train, {len(test_df)} test.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c64f1804-b6a8-4bcf-acc2-1bde66ddd20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained and saved to policy_vectorizer.pkl and policy_tfidf_matrix.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "MODEL_PATH = \"policy_vectorizer.pkl\"\n",
    "MATRIX_PATH = \"policy_tfidf_matrix.pkl\"\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "full_df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Preprocess both\n",
    "train_df = preprocess(train_df)\n",
    "full_df = preprocess(full_df)\n",
    "\n",
    "# Train TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "vectorizer.fit(train_df[\"text_for_nlp\"])\n",
    "\n",
    "# Transform full data\n",
    "tfidf_matrix = vectorizer.transform(full_df[\"text_for_nlp\"])\n",
    "\n",
    "# Save model & matrix\n",
    "joblib.dump(vectorizer, MODEL_PATH)\n",
    "joblib.dump({\"matrix\": tfidf_matrix, \"df\": full_df}, MATRIX_PATH)\n",
    "\n",
    "print(f\"✅ Model trained and saved to {MODEL_PATH} and {MATRIX_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0dc42aa-8a70-4225-9870-36831ace837d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (500, 1318), Sparsity: 7.12%\n",
      "Top 20 words/phrases by TF-IDF importance:\n",
      "and: 44.78\n",
      "to: 40.11\n",
      "education: 31.80\n",
      "state: 22.28\n",
      "reform: 21.28\n",
      "includes: 21.27\n",
      "learning: 21.09\n",
      "improve: 21.03\n",
      "on: 20.98\n",
      "set: 20.71\n",
      "strengthen: 20.62\n",
      "monitoring: 19.62\n",
      "community: 19.61\n",
      "by: 18.69\n",
      "goals: 18.55\n",
      "stakeholders: 18.55\n",
      "education reform: 18.55\n",
      "vocational: 18.55\n",
      "outcomes: 18.53\n",
      "teachers: 18.34\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Summary\n",
    "num_docs, num_terms = tfidf_matrix.shape\n",
    "sparsity = (tfidf_matrix.nnz / (num_docs * num_terms)) * 100\n",
    "print(f\"TF-IDF matrix shape: ({num_docs}, {num_terms}), Sparsity: {sparsity:.2f}%\")\n",
    "\n",
    "# Compute top 20 words/phrases by total TF-IDF weight\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "tfidf_sums = np.array(tfidf_matrix.sum(axis=0)).flatten()\n",
    "top_indices = tfidf_sums.argsort()[::-1][:20]\n",
    "\n",
    "print(\"Top 20 words/phrases by TF-IDF importance:\")\n",
    "for term, score in zip(feature_names[top_indices], tfidf_sums[top_indices]):\n",
    "    print(f\"{term}: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7184d-3b2d-4930-abd0-b0eb4b007eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
